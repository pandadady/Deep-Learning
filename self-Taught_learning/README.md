#Self-Taught Learning
##1.Summary
    
        The most efficent method of ML or DL algorithm improvinng is to provide more traning data.
    
    Manual marking is known as the important method of training data production. Its disadvantage 
    
    is low efficiency and high cost of labor. Unsupervised feature learning is builded to solve those problem.
    
    It is able to learning features from unlabeled training data. Even though a single unlabeled example 
    
    is less informative than a single labeled example, the number of unlabeled data is much more than 
    
    that of the labeled data. When DL or ML algorithm is able to exploit this unlabeled data effectively,
    
    then we might be able to achieve better performance than the massive hand-engineering and massive 
    
    hand-labeling approaches.
    
        There are 2 kinds of common Unsupervised feature learning, Semi-supervised learning and self-Taught 
        
    Learning.Semi-supervised learning demands unlabeled data comes from exactly the same distribution as 
    
    the labeled data. Self-Taught Learning don't have this restriction. For example, you need to recognize apple 
    
    image and pear image, semi-supervised learning use unlabeled apple image and pear image, self-Taught Learning 
    
    use unlabeled images which have some apple image ,pear image and other image.This is the magic of self-Taught 
    
    Learning.
    
##2.Process
    
<img alt="STL SparseAE Features.png" src="http://ufldl.stanford.edu/wiki/images/7/73/STL_SparseAE_Features.png" width="300" height="497" />
    
        This is structure of self-Taught Learning model. Actuallyï¼Œ it is sparse autoencoder model without last layer.
        
    There is 2 ways to use this algorithm, replacement representation and concatenated representation.
    
###(1)Replacement representation

    
    
